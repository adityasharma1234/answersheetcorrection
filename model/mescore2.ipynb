{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"DATASET_DIR = \"../input/automated-essay-scoring-dataset/\"\nGLOVE_DIR = './glove.6B/'\nSAVE_DIR = './'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.read_csv(os.path.join(DATASET_DIR, 'training_set_rel3.tsv'), sep='\\t', encoding='ISO-8859-1')\ny = X['domain1_score']\nX = X.dropna(axis=1)\nX = X.drop(columns=['rater1_domain1', 'rater2_domain1'])\n\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom gensim.models import Word2Vec\nminimum_scores = [-1, 2, 1, 0, 0, 0, 0, 0, 0]\nmaximum_scores = [-1, 12, 6, 3, 3, 4, 4, 30, 60]\n\n\ndef toword(es, remove_stopwords):\n\n    es = re.sub(\"[^a-zA-Z]\", \" \", es)\n    words = es.lower().split()\n    if remove_stopwords:\n        stop = set(stopwords.words(\"english\"))\n        w = [w for w in words if not w in stop]\n    return (w)\n\n\ndef tosentence(es, remove_stopwords):\n\n    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n    initialsentence = tokenizer.tokenize(es.strip())\n    s = []\n    for r in initialsentence:\n        if len(r) > 0:\n            s.append(toword(r, remove_stopwords))\n    return s\n\n\ndef make_feature(w, model, numberoffeaturess):\n    f_vector = np.zeros((numberoffeaturess,),dtype=\"float32\")\n    numberofwords = 0.\n    indexset = set(model.wv.index2word)\n    for word in w :\n        if word in indexset:\n            numberofwords += 1\n            f_vector = np.add(f_vector,model[word])\n    return f_vector\n\ndef AverageFeature(essays, model, num_features):\n   \n    num_words = 0\n    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n    for essay in essays:\n        essayFeatureVecs[num_words] = make_feature(essay, model, num_features)\n        num_words =num_words + 1\n    return essayFeatureVecs\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential, load_model, model_from_config\nfrom tensorflow.keras.layers import Embedding, LSTM, GRU,Dense, Dropout, Lambda, Flatten\n#from tensorflow.keras.models import Sequential, load_model, model_from_config\nimport tensorflow.keras.backend as K\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import cohen_kappa_score\n\ndef get_model():\n\n    model = Sequential()\n    model.add(GRU(200, dropout=0.6, recurrent_dropout=0.6, input_shape=[1, 200], return_sequences=True))\n    model.add(GRU(64, recurrent_dropout=0.6))\n    model.add(Dropout(0.7))\n    model.add(Dense(1, activation='relu'))\n\n    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n    model.summary()\n    return model\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = KFold(n_splits=5, shuffle=True)\nresults = []\npredictionlist = []\n\ncount = 1\nfor traincv, testcv in cv.split(X):\n\n    print(\"\\n--------Fold {}--------\\n\".format(count))\n    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n\n    train = X_train['essay']\n    test = X_test['essay']\n\n    s = []\n    for e in train:\n        s +=tosentence(e, remove_stopwords = True)\n    numberoffeaturess = 200\n    minimumword = 40\n    numberofworker = 4\n    contet = 10\n    downsampling = 1e-3\n    model =Word2Vec(s, workers=numberofworker, size=numberoffeaturess, min_count = minimumword, window = contet, sample = downsampling)\n    model.init_sims(replace=True)\n    model.wv.save_word2vec_format(\"model1.bin\", binary =True )\n    c_train = []\n    for es in train:\n        c_train.append(toword(es, remove_stopwords=True))\n    trainvector = AverageFeature(c_train, model, numberoffeaturess)\n    c_test = []\n    for es in test:\n        c_test.append(toword( es, remove_stopwords=True ))\n    testvector = AverageFeature( c_test, model, numberoffeaturess )\n    trainvector = np.array(trainvector)\n    testvector = np.array(testvector)\n    trainvector = np.reshape(trainvector, (trainvector.shape[0], 1, trainvector.shape\n    [1]))\n    testvector = np.reshape(testvector, (testvector.shape[0], 1, testvector.shape[1]))\n\n    model1 = get_model()\n    model1.fit(trainvector, y_train, batch_size=64, epochs=15)\n    yprediction = model1.predict(testvector)\n    if count == 5:\n         model1.save('./model_gru.h5')\n    yprediction = np.around(yprediction)\n    result = cohen_kappa_score(y_test.values,yprediction,weights='quadratic')\n    print(\"Kappa Score: {}\".format(result))\n    results.append(result)\n\n    count += 1\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Average score \",np.around(np.array(results).mean(),decimals=2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n1, n2, n3 = trainvector.shape\nx_train = trainvector.reshape((n1,n2*n3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nm1 = RandomForestClassifier(n_estimators= 200 , criterion='entropy')\nm1.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n4, n5, n6 = testvector.shape\nx_test = testvector.reshape((n4,n5*n6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVR\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred1 = m1.predict(x_test )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test, y_pred1))\nprint(classification_report(y_test, y_pred1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('randomforestaccurracy {:.2f}'\n     .format(m1.score(x_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR\n\nm2 = SVR()\n\nm2.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred2 = m2.predict(x_test )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(' svr accurracy {:.2f}'\n     .format(m2.score(x_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}